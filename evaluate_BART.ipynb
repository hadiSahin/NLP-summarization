{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/labeled01.csv\", encoding='cp1252')\n",
    "df2 = pd.read_csv(\"data/summaries_t5.csv\")\n",
    "df3 = pd.read_csv(\"data/summaries_bart.csv\")\n",
    "df4 = pd.read_csv(\"data/summaries_pgs.csv\")\n",
    "df = pd.DataFrame()\n",
    "df['human_summary'] = df1['summary'][0:26]\n",
    "df['t5_summary'] = df2['summary'][0:26]\n",
    "df['bart_summary'] = df3['summary'][0:26]\n",
    "df['pgs_summary'] = df4['summary'][0:26]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Load the trained model\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\"data/results_fineTuning/BART/checkpoint-1045\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Define a function to generate summaries\n",
    "def generate_summary(text, model, tokenizer):\n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', max_length=800, truncation=True)\n",
    "    \n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(input_ids, do_sample=True, max_new_tokens=50, min_length=10)\n",
    "    \n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words('english')) \n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text #remove links\n",
    "    # newString = re.sub(r'\\([^)]*\\)', '', newString) # remove text in the paranthesis\n",
    "    newString = re.sub('_','', newString) # removing underscores\n",
    "    newString = re.sub('\"','', newString) # removing double quotes\n",
    "    newString = re.sub('/',' ', newString) # removing double quotes\n",
    "    newString = re.sub('-','', newString) # removing double quotes\n",
    "    newString = re.sub(r'[^\\x00-\\x7F]+', '', newString) # removes non-ASCII characters\n",
    "    # newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString) #remove possesive s\n",
    "    # newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    # if(num==0):\n",
    "    #     tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    # else:\n",
    "    #     tokens=newString.split()\n",
    "    tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resolution</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resolution of the miami city commission accept...</td>\n",
       "      <td>The Miami City Commission accepted bids from r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resolution of the miami city commission findin...</td>\n",
       "      <td>The Miami City Commission found that the COVID...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resolution of the miami city commission author...</td>\n",
       "      <td>Miami City Commission authorizes city manager ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resolution of the miami city commission, with ...</td>\n",
       "      <td>Miami City Commission accepts perpetual sidewa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resolution of the miami city commission, with ...</td>\n",
       "      <td>Miami City Commission accepts two right-of-way...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          resolution  \\\n",
       "0  resolution of the miami city commission accept...   \n",
       "1  resolution of the miami city commission findin...   \n",
       "2  resolution of the miami city commission author...   \n",
       "3  resolution of the miami city commission, with ...   \n",
       "4  resolution of the miami city commission, with ...   \n",
       "\n",
       "                                             summary  \n",
       "0  The Miami City Commission accepted bids from r...  \n",
       "1  The Miami City Commission found that the COVID...  \n",
       "2  Miami City Commission authorizes city manager ...  \n",
       "3  Miami City Commission accepts perpetual sidewa...  \n",
       "4  Miami City Commission accepts two right-of-way...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df1.iloc[0:26]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the summaries\n",
    "summaries = []\n",
    "\n",
    "for text in df_test['resolution']:\n",
    "    summary = generate_summary(text_cleaner(text,0), model, tokenizer)\n",
    "    summaries.append(summary)\n",
    "\n",
    "# Create a new DataFrame with the summaries\n",
    "summary_df = pd.DataFrame({'summary': summaries})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# summary_df.to_csv('summaries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bids received on february 18, 2021 pursuant to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The novel coronavirus 2019 pandemic has caused...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary\n",
       "0  Bids received on february 18, 2021 pursuant to...\n",
       "1  The novel coronavirus 2019 pandemic has caused..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv(\"data/results_fineTuning/BART/eval_bart_1045.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BART_418_summary'] = summary_df['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_summary</th>\n",
       "      <th>t5_summary</th>\n",
       "      <th>bart_summary</th>\n",
       "      <th>pgs_summary</th>\n",
       "      <th>BART_418_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Miami City Commission accepted bids from r...</td>\n",
       "      <td>miami city commission accepts bids for bio haz...</td>\n",
       "      <td>Bids received on february 18, 2021 pursuant to...</td>\n",
       "      <td>City commission meeting agenda January 13, 202...</td>\n",
       "      <td>Bids received on february 18, 2021 pursuant to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Miami City Commission found that the COVID...</td>\n",
       "      <td>miami city commission finds coronavirus 2019 p...</td>\n",
       "      <td>The city commission found that the novel coron...</td>\n",
       "      <td>The commission finds that the novel coronaviru...</td>\n",
       "      <td>The novel coronavirus 2019 pandemic has caused...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       human_summary  \\\n",
       "0  The Miami City Commission accepted bids from r...   \n",
       "1  The Miami City Commission found that the COVID...   \n",
       "\n",
       "                                          t5_summary  \\\n",
       "0  miami city commission accepts bids for bio haz...   \n",
       "1  miami city commission finds coronavirus 2019 p...   \n",
       "\n",
       "                                        bart_summary  \\\n",
       "0  Bids received on february 18, 2021 pursuant to...   \n",
       "1  The city commission found that the novel coron...   \n",
       "\n",
       "                                         pgs_summary  \\\n",
       "0  City commission meeting agenda January 13, 202...   \n",
       "1  The commission finds that the novel coronaviru...   \n",
       "\n",
       "                                    BART_418_summary  \n",
       "0  Bids received on february 18, 2021 pursuant to...  \n",
       "1  The novel coronavirus 2019 pandemic has caused...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1: {'r': 0.38355378056345973, 'p': 0.288331539606961, 'f': 0.3228767577814674}\n",
      "Average ROUGE-2: {'r': 0.17010615469454857, 'p': 0.11427278230890749, 'f': 0.1330255666626716}\n",
      "Average ROUGE-L: {'r': 0.34600279054073196, 'p': 0.26010780648798854, 'f': 0.29110963720972827}\n",
      "Average BLEU score: 0.0559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# rouge = Rouge()\n",
    "# rouge_scores_pgs = [rouge.get_scores(row['T5_2717_summary'], row['human_summary']) for _, row in df.iterrows()]\n",
    "\n",
    "# # prepare data for bleu calculation\n",
    "# nlp_summaries_lists = [[summary.split()] for summary in df['T5_2717_summary']]\n",
    "# human_summaries_lists = [summary.split() for summary in df['human_summary']]\n",
    "# bleu_score_pgs = corpus_bleu(nlp_summaries_lists, human_summaries_lists)\n",
    "\n",
    "# print('ROUGE scores:', rouge_scores_pgs)\n",
    "# print('BLEU score:', bleu_score_pgs)\n",
    "\n",
    "\n",
    "\n",
    "rouge = Rouge()\n",
    "total_rouge_1 = {'r': 0, 'p': 0, 'f': 0}\n",
    "total_rouge_2 = {'r': 0, 'p': 0, 'f': 0}\n",
    "total_rouge_l = {'r': 0, 'p': 0, 'f': 0}\n",
    "num_rows = len(df)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    rouge_scores = rouge.get_scores(row['BART_418_summary'], row['human_summary'])[0]\n",
    "    for metric in ['rouge-1', 'rouge-2', 'rouge-l']:\n",
    "        for score_type in ['r', 'p', 'f']:\n",
    "            if metric == 'rouge-1':\n",
    "                total_rouge_1[score_type] += rouge_scores[metric][score_type]\n",
    "            elif metric == 'rouge-2':\n",
    "                total_rouge_2[score_type] += rouge_scores[metric][score_type]\n",
    "            else:\n",
    "                total_rouge_l[score_type] += rouge_scores[metric][score_type]\n",
    "\n",
    "avg_rouge_1 = {score_type: total_rouge_1[score_type] / num_rows for score_type in ['r', 'p', 'f']}\n",
    "avg_rouge_2 = {score_type: total_rouge_2[score_type] / num_rows for score_type in ['r', 'p', 'f']}\n",
    "avg_rouge_l = {score_type: total_rouge_l[score_type] / num_rows for score_type in ['r', 'p', 'f']}\n",
    "\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "df['bleu_score'] = df.apply(lambda row: sentence_bleu([row['human_summary'].split()], row['BART_418_summary'].split()), axis=1)\n",
    "avg_bleu_score = df['bleu_score'].mean()\n",
    "\n",
    "\n",
    "print(f'Average ROUGE-1: {avg_rouge_1}')\n",
    "print(f'Average ROUGE-2: {avg_rouge_2}')\n",
    "print(f'Average ROUGE-L: {avg_rouge_l}')\n",
    "print(f'Average BLEU score: {avg_bleu_score:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
